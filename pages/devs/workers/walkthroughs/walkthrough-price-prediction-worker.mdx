import { Callout } from 'nextra/components'

# Walkthrough: Build and Deploy Price Prediction Worker Node

> How to build a node that predicts the future price of Ether

## Prerequisites 

1. Make sure you have checked the documentation on how to [build and deploy a worker node using Docker](/devs/workers/deploy-worker/using-docker).
2. Clone the [basic-coin-prediction-node](https://github.com/allora-network/basic-coin-prediction-node) repository. It will serve as the base sample for your quick setup.

```bash
git clone https://github.com/allora-network/basic-coin-prediction-node
cd basic-coin-prediction-node
```

## Configure Your Environment

### `.env` File Configuration

When setting up your environment, please follow the guidelines below for configuring your `.env` file:

- **`TOKEN`**: Specifies the cryptocurrency token to use. Must be one of the following:
  - `'ETH'` (Ethereum)
  - `'SOL'` (Solana)
  - `'BTC'` (Bitcoin)
  - `'BNB'` (Binance Coin)
  - `'ARB'` (Arbitrum)
  
  > **Note**: If you are using Binance as the data provider, any token can be used. However, if you are using Coingecko, you should add its `coin_id` in the [token map](https://github.com/allora-network/basic-coin-prediction-node/blob/70cf49d0a2317769d883ae882c146efbb915f5c0/updater.py#L107). Find more information [here](https://docs.coingecko.com/reference/simple-price) and the list [here](https://docs.google.com/spreadsheets/d/1wTTuxXt8n9q7C4NDXqQpI3wpKu1_5bGVmP9Xz0XGSyU/edit?gid=0#gid=0).

- **`TRAINING_DAYS`**: Represents the number of days of historical data to use for training. Must be an integer greater than or equal to 1.

- **`TIMEFRAME`**: Defines the timeframe of the data used in the format like `10min` (minutes), `1h` (hours), `1d` (days), etc.
  
  - For Coingecko, the data granularity (candle's body) is automatic. To avoid downsampling when using Coingecko:
    - Use a **`TIMEFRAME`** of `>= 30min` if **`TRAINING_DAYS`** is `<= 2`.
    - Use a **`TIMEFRAME`** of `>= 4h` if **`TRAINING_DAYS`** is `<= 30`.
    - Use a **`TIMEFRAME`** of `>= 4d` if **`TRAINING_DAYS`** is `>= 31`.

- **`MODEL`**: Specifies the machine learning model to use. Must be one of the following:
  - `'LinearRegression'`
  - `'SVR'` (Support Vector Regression)
  - `'KernelRidge'`
  - `'BayesianRidge'`
  
  > You can easily add support for other models by adding them to the configuration [here](https://github.com/allora-network/basic-coin-prediction-node/blob/main/model.py#L133).

- **`REGION`**: Defines the region for the Binance API. Must be `'EU'` or `'US'`.

- **`DATA_PROVIDER`**: Specifies the data provider to use. Must be either `'Binance'` or `'Coingecko'`.
  
  - Feel free to add support for other data providers to personalize your model!

- **`CG_API_KEY`**: Your Coingecko API key, required if you've set **`DATA_PROVIDER`** to `'coingecko'`.

#### Sample Configuration (.env file)

Below is an example configuration for your `.env` file:

```bash
TOKEN=ETH
TRAINING_DAYS=30
TIMEFRAME=4h
MODEL=SVR
REGION=US
DATA_PROVIDER=binance
CG_API_KEY=
```

### `config.json` Configuration

1. Copy `config.example.json` and name the copy `config.json`.
2. Open `config.json` and **update** the necessary fields inside the `wallet` sub-object and `worker` config with your specific values:

#### `wallet` Sub-object

1. `nodeRpc`: The [RPC URL](/devs/get-started/setup-wallet#rpc-url-and-chain-id) for the corresponding network the node will be deployed on
2. `addressKeyName`: The name you gave your wallet key when [setting up your wallet](/devs/get-started/setup-wallet)
3. `addressRestoreMnemonic`: The mnemonic that was outputted when setting up a new key

{/* <Callout type="info">
`addressKeyName` and `addressRestoreMnemonic` are optional parameters. If you did not previously generate keys, keys will be generated for you when [running the node](/devs/workers/deploy-worker/using-docker#generate-keys-and-export-variables).

If you have existing keys that you wish to use, you will need to provide these variables.
</Callout> */}

#### `worker` Config

1. `topicId`: The specific topic ID you created the worker for. 
2. `InferenceEndpoint`: The endpoint exposed by your worker node to provide inferences to the network.
3. `Token`: The token for the specific topic you are providing inferences for. The token needs to be exposed in the inference server endpoint for retrieval.
  - The `Token` variable is specific to the endpoint you expose in your `main.py` file. It is not related to any topic parameter.

<Callout type="warning">
The `worker` config is an array of sub-objects, each representing a different topic ID. This structure allows you to manage multiple topic IDs, each within its own sub-object.

To deploy a worker that provides inferences for multiple topics, you can duplicate the existing sub-object and add it to the `worker` array. Update the `topicId`, `InferenceEndpoint` and `Token` fields with the appropriate values for each new topic:
```json
"worker": [
      {
        "topicId": 1,
        "inferenceEntrypointName": "api-worker-reputer",
        "loopSeconds": 5,
        "parameters": {
          "InferenceEndpoint": "http://localhost:8000/inference/{Token}",
          "Token": "ETH"
        }
      },
      // worker providing inferences for topic ID 2
      {
        "topicId": 2, 
        "inferenceEntrypointName": "api-worker-reputer",
        "loopSeconds": 5,
        "parameters": {
          "InferenceEndpoint": "http://localhost:8000/inference/{Token}", // the specific endpoint providing inferences
          "Token": "ETH" // The token specified in the endpoint
        }
      }
    ],
```
</Callout>

## Building a Custom Model

`basic-coin-prediction-node` comes preconfigured with a model that uses regression to predict the price of Ethereum, and contribute an inference to topic 1 on Allora. Learn more about how this model is built from the ground up and how you can customize your model to give a unique inference to the network in the [next section](/devs/workers/walkthroughs/walkthrough-price-prediction-worker/modelpy).

## Deployment

Now that the node is configured, let's deploy and register it to the network. To run the node, follow these steps:

### Export Variables

Execute the following command from the root directory:

```sh
chmod +x init.config
./init.config 
```

This command will automatically export the necessary variables from the account created. These variables are used by the offchain node and are bundled with your provided `config.json`, then passed to the node as environment variables.

<Callout>
If you need to **make changes** to your `config.json` file after you ran the `init.config` command, rerun:

```sh
chmod +x init.config
./init.config 
```

before proceeding.

</Callout>

### Request from Faucet

Copy your Allora address and request some tokens from the [Allora Testnet Faucet](https://faucet.testnet.allora.network/) to register your worker in the next step successfully.

### Deploy the Node

```
docker compose up --build
```

Both the offchain node and the source services will be started. They will communicate through endpoints attached to the internal DNS.

If your node is working correctly, you should see it actively checking for the active worker nonce:

```bash
offchain_node    | {"level":"debug","topicId":1,"time":1723043600,"message":"Checking for latest open worker nonce on topic"}
```

A **successful** response from your Worker should display:

```bash
{"level":"debug","msg":"Send Worker Data to chain","txHash":<tx-hash>,"time":<timestamp>,"message":"Success"}
```

Congratulations! You've successfully deployed and registered your node on Allora.

### Testing

You can test your local inference server by performing a `GET` request on `http://localhost:8000/inference/<token>`.

```bash
curl http://localhost:8000/inference/<token>
```

