import { Callout } from 'nextra/components'

# Build and Deploy a Worker Node

This document outlines a setup where the worker node is supported by an inference server. Communication occurs through an endpoint, allowing the worker to request inferences from the server.

To build this setup, please follow these steps:

## Prerequisites

Ensure you have the following installed on your machine:

- Git
- Go (version 1.16 or later)

## Clone the `allora-offchain-node` Repository

Download the `allora-offchain-node` git repo:

```bash
git clone https://github.com/allora-network/allora-offchain-node
cd allora-offchain-node
```

## Install Dependencies

```bash
go mod download
```

## Configure Your Environment

1. Copy `config.example.json` and name the copy `config.json`.
2. Open `config.example.json` and **update** the necessary fields inside the `wallet` sub-object and `worker` config with your specific values:

### `wallet` Sub-object

1. `addressKeyName`: The name you gave your wallet key when [setting up your wallet](/devs/get-started/setup-wallet)
2. `addressRestoreMnemonic`: The mnemonic that was outputted when setting up a new key
4. `nodeRpc`: The [RPC URL](/devs/get-started/setup-wallet#rpc-url-and-chain-id) for the corresponding network the node will be deployed on

<Callout type="warning">
Please make sure your wallet is properly funded, or your node will not be able to pay the registration fee and connect to the network.

To fund your wallet, enter your wallet address into [the Allora Testnet faucet](https://faucet.testnet-1.testnet.allora.network/) and press 'Request Funds'.
</Callout>

### `worker` Config

1. `topicId`: The specific topic ID you created the worker for. 
2. `InferenceEndpoint`: The endpoint exposed by your worker node to provide inferences to the network.
3. `Token`: The token for the specific topic you are providing inferences for. The token needs to be exposed in the inference server endpoint for retrieval.
  - The `Token` variable is specific to the endpoint you expose in your `main.py` file. It is not related to any topic parameter.

<Callout type="warning">
The `worker` config is an array of sub-objects, each representing a different topic ID. This structure allows you to manage multiple topic IDs, each within its own sub-object.

To deploy a worker that provides inferences for multiple topics, you can duplicate the existing sub-object and add it to the `worker` array. Update the `topicId`, `InferenceEndpoint` and `Token` fields with the appropriate values for each new topic:
```json
"worker": [
      {
        "topicId": 1,
        "inferenceEntrypointName": "api-worker-reputer",
        "loopSeconds": 5,
        "parameters": {
          "InferenceEndpoint": "http://localhost:8000/inference/{Token}",
          "Token": "ETH"
        }
      },
      // worker providing inferences for topic ID 2
      {
        "topicId": 2, 
        "inferenceEntrypointName": "api-worker-reputer",
        "loopSeconds": 5,
        "parameters": {
          "InferenceEndpoint": "http://localhost:8000/inference/{Token}", // the specific endpoint providing inferences
          "Token": "ETH" // The token specified in the endpoint
        }
      }
    ],
```
</Callout>

## Create the Inference Server

### Prepare the API Gateway

Ensure you have an API gateway or server that can accept API requests to call your model.

### Server Responsibilities

- Accept API requests from `main.go`.
- Respond with the corresponding inference obtained from the model.

### Inference Relay

Below is a sample structure of what your `main.go`, `main.py` and Dockerfile will look like. You can also find a working example [here](https://github.com/allora-network/basic-coin-prediction-node).

#### `main.go`

`allora-offchain-node` comes preconfigured with a `main.go` file inside the [`adapter/api-worker-reputer` folder](https://github.com/allora-network/allora-offchain-node/blob/dev/adapter/api-worker-reputer/main.go).

The `main.go` file fetches the responses outputted from the Inference Endpoint based on the `InferenceEndpoint` and `Token` provided in the section above.

#### `main.py`

`allora-offchain-node` comes preconfigured with a Flask application that uses a `main.py` file to expose the Inference Endpoint. 

The Flask application serves the request from `main.go`, which is routed to the `get_inference`  function using the required argument (`Token`). Before proceeding, ensure that all necessary packages are listed in the `requirements.txt` file.

```python
from flask import Flask
from model import get_inference  # Importing the hypothetical model

app = Flask(__name__)

@app.route('inference/<argument>')
def get_inference(param):
    random_float = str(random.uniform(0.0, 100.0))
    return random_float

if __name__ == '__main__':
    app.run(host='0.0.0.0')
```

<Callout type="warning">
  The model in `allora-offchain-node` is barebones and outputs a random integer. Follow the model built in [`basic-coin-prediction-node`](https://github.com/allora-network/basic-coin-prediction-node) as an example for a full model that uses linear regression to provide an inference.

  A full breakdown of the components needed to build the model is available [here](/devs/workers/walkthroughs/walkthrough-price-prediction-worker).
</Callout>

## Running the Node

Now that the node is configured, let's deploy and register it to the network. To run the node, follow these steps:

### Generate Keys and Export Variables

Execute the following command from the root directory:

```sh
chmod +x start.local
./start.local
```

This command will handle a couple tasks automatically:

1. **Key Creation**: Docker Compose will automatically create Allora keys for you.

<Callout type="info">
If you've already specified a predefined key and mnemonic, this command will recognize those and export the predefined values instead of overriding them.
</Callout>

2. **Export Variables**: The system will automatically export the necessary variables from the account created. These variables are used by the offchain node and are bundled with your provided `config.json`, then passed to the node as environment variables.

<Callout>
If you need to **make changes** to your `config.json` file after you ran the `init.config` command:

1. Go to `./worker-data/env_file`
2. Set `ENV_LOADED` to `false`
3. Rerun:
```sh
chmod +x init.config
./init.config 
```
</Callout>

### Request from Faucet

1. Find your Allora address in `./worker-data/env_file` if you haven't already specified a predefined key and mnemonic.
2. Request some tokens from the [Allora Testnet Faucet](https://faucet.testnet-1.testnet.allora.network/) to register your worker in the next step successfully.

### Deploy the Node

```
chmod +x start.local
./start.local
```

Both the offchain node and the source services will be started. They will communicate through endpoints attached to the internal DNS.

If your node is working correctly, you should see it actively checking for the active worker nonce:

```bash
offchain_node    | {"level":"debug","topicId":1,"time":1723043600,"message":"Checking for latest open worker nonce on topic"}
```

A **successful** response from your Worker should display:

```bash
{"level":"debug","msg":"Send Worker Data to chain","txHash":<tx-hash>,"time":<timestamp>,"message":"Success"}
```

Congratulations! You've successfully deployed and registered your node on Allora.

You can test your local inference server by performing a `GET` request on `http://localhost:8000/inference/<token>`.

## Deploying a Worker Node to Production

Now that you have built and tested your worker node, Your next goal will be to deploy it to production, where it runs forever. to do that, we use the Kubernetes cluster and Upshot Universal-helm chart. While you can deploy your node however you wish, you can also follow these steps if you are not opinionated on deployment.

### Build, Tag, and push your Dockerfile

The first step toward deployment is pushing your Docker image to your preferred repository. The Universal-helm chart will use the pushed image to deploy the worker node to your Kubernetes cluster.

```shell
#login to docker repository eg Docker Hub
docker login

#tag your image
docker tag image-name:tag username/repository:tag

#push image to repository
docker push username/repository:tag
```

### Add Universal-helm to Helm Repository

On your Kubernetes cluster on your preferred cloud service, you will have to add the universal-helm repository to your cluster.

```shell
helm repo add upshot https://upshot-tech.github.io/helm-charts
```

### Create `values.yaml` File

Provide custom values in a `values.yaml` file.

```yaml
statefulsets:
  - name: worker
    replicas: 1
    persistence:
      size: 1Gi
      storageClassName: gp2
      volumeMountPath: /data
    initContainers:
      - name: initialize-keys
        image: {image}:{tag}
        env:
          - name: APP_HOME
            value: "/data"
        workingDir: /data
        command:
          - /bin/sh
          - -c
          - |
            KEYS_PATH="${APP_HOME}/keys"

            if [ -d "$KEYS_PATH" ]; then
              echo "Keys exist"
            else
              echo "Generating New Node Identity"
              mkdir -p ${APP_HOME}/keys
              cd $KEYS_PATH
              allora-keys
            fi
        volumeMounts:
          - name: workers-data
            mountPath: /data
        securityContext:
          runAsUser: 1001

      - name: init-allora-account
        image: alloranetwork/allora-chain:latest
        env:
          - name: APP_HOME
            value: "/data"
          - name: SECRETS_DIR
            value: "/keys"
        workingDir: /data
        command:
          - /bin/sh
          - -c
          - |
            set -ex

            ACCOUNT_NAME=<account name>
            KEYRING_BACKEND=test 

            if allorad keys --keyring-backend $KEYRING_BACKEND show $ACCOUNT_NAME >/dev/null 2>&1 ; then
              echo "$ACCOUNT_NAME - account already imported"
            else
              allorad keys import-hex --home=${APP_HOME}/.allorad --keyring-backend $KEYRING_BACKEND $ACCOUNT_NAME <exported hex private key>
            fi
        securityContext:
          runAsUser: 1001
        volumeMounts:
          - name: worker-data
            mountPath: /data

    containers:
      - name: worker
        image:
          repository: <image>
          tag: <tag>
        env:
          - name: APP_HOME
            value: "/data"
        workingDir: /data
        command:
          - allora-node
          - --role=worker
          - --peer-db=$(APP_HOME)/peer-database
          - --function-db=$(APP_HOME)/function-database
          - --runtime-path=/app/runtime
          - --runtime-cli=bls-runtime
          - --workspace=/tmp/node
          - --private-key=$(APP_HOME)/keys/priv.bin
          - --log-level=debug
          - --port=9010
          - --boot-nodes=/dns4/head-0.testnet.allora.network/tcp/9010/p2p/12D3KooWGAA1C2UNyj51QaGX5aXnVzRqeaqhyhUFFJixdqshwWC3
          - --allora-node-rpc-address=http://sentry-allorad-rpc.testnet-sentries:26657
          - --allora-chain-home-dir=/data/.allorad
          - --allora-chain-key-name=<account name>
          - --allora-chain-topic-id=<preferred topic id>
          - --topic=<preferred topic id>
        ports:
          - name: p2p
            port: 9100
        resources:
          limits:
            cpu: 1
            memory: 1Gi
          requests:
            cpu: 256m
            memory: 512Mi
        startupProbe:
          tcpSocket:
            port: 9100
          periodSeconds: 10
          failureThreshold: 6
        livenessProbe:
          tcpSocket:
            port: 9100
global:
  serviceAccount:
    name: node
  securityContext:
    fsGroup: 1001
    runAsUser: 1001
    runAsGroup: 1001
    fsGroupChangePolicy: "Always"

```

> Note: Please replace the variables parameter in. `<>` respectively

### Install Helm Chart

```shell
helm install index-provider upshot/universal-helm -f values.yaml
```

If all these are done correctly, your worker node should run successfully in your cloud cluster.
